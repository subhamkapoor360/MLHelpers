{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cactus Identification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhamkapoor360/MLHelpers/blob/master/Cactus_Identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3vcssk01A9L",
        "colab_type": "code",
        "outputId": "6fbbd123-5297-4147-96c3-50ca40057cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive/',force_remount=True)\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF7ZTZ2J6mxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import img_to_array,load_img\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv3D, MaxPooling3D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3wzRU9T3eUK",
        "colab_type": "code",
        "outputId": "aa5bfd41-2a5f-49c4-c461-0b2d5341e154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls \"/content/drive/My Drive/Datasets/cactus-identification/\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_submission.csv  test  test.zip  train  train.csv  train.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lue-0QMo6yTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_DIR = \"/content/drive/My Drive/Datasets/cactus-identification/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N_0IZkP3fBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"{}{}\".format(BASE_DIR,'train.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMca7fDe4czu",
        "colab_type": "code",
        "outputId": "615b0360-7758-4e0e-f5b4-8257c3b4d7b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "train.head(2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>has_cactus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     id  has_cactus\n",
              "0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
              "1  000c8a36845c0208e833c79c1bffedd1.jpg           1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i0l7Opv9pgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip '/content/drive/My Drive/Datasets/cactus-identification/train.zip'\n",
        "!unzip '/content/drive/My Drive/Datasets/cactus-identification/test.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZJX_UmR9rFY",
        "colab_type": "code",
        "outputId": "dd68746e-3926-4a1c-d94b-d83cd487681d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /content/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data  test  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCHb6cI__h-H",
        "colab_type": "code",
        "outputId": "2fa5fb60-3fc1-4d46-f824-fd43a0338849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "train.head(2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>has_cactus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     id  has_cactus\n",
              "0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
              "1  000c8a36845c0208e833c79c1bffedd1.jpg           1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65vXs0n2AHBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/content/'\n",
        "if not os.path.exists(base_dir):\n",
        "  os.mkdir(base_dir)\n",
        "\n",
        "\n",
        "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
        "\n",
        "# now we create 2 folders inside 'base_dir':\n",
        "\n",
        "# train_dir\n",
        "    # has_cactus\n",
        "    # has_no_cactus\n",
        "\n",
        "# val_dir\n",
        "    # has_cactus\n",
        "    # has_no_cactus\n",
        "\n",
        "\n",
        "\n",
        "# create a path to 'base_dir' to which we will join the names of the new folders\n",
        "# train_dir\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "if not os.path.exists(train_dir):\n",
        "  os.mkdir(train_dir)\n",
        "\n",
        "# val_dir\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "if not os.path.exists(val_dir):\n",
        "  os.mkdir(val_dir)\n",
        "\n",
        "\n",
        "\n",
        "# [CREATE FOLDERS INSIDE THE TRAIN AND VALIDATION FOLDERS]\n",
        "# Inside each folder we create seperate folders for each class\n",
        "\n",
        "# create new folders inside train_dir\n",
        "has_cactus = os.path.join(train_dir, 'has_cactus')\n",
        "if not os.path.exists(has_cactus):\n",
        "  os.mkdir(has_cactus)\n",
        "has_no_cactus = os.path.join(train_dir, 'has_no_cactus')\n",
        "if not os.path.exists(has_no_cactus):\n",
        "  os.mkdir(has_no_cactus)\n",
        "\n",
        "\n",
        "# create new folders inside val_dir\n",
        "has_cactus = os.path.join(val_dir, 'has_cactus')\n",
        "if not os.path.exists(has_cactus):\n",
        "  os.mkdir(has_cactus)\n",
        "has_no_cactus = os.path.join(val_dir, 'has_no_cactus')\n",
        "if not os.path.exists(has_no_cactus):\n",
        "  os.mkdir(has_no_cactus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_nhWq1HAwyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.index = train.id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbXiabHzCj7j",
        "colab_type": "code",
        "outputId": "7381b9b2-f82c-4f23-e4dc-f061463f3a91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "df_train, df_val = train_test_split(train, test_size=0.20, random_state=101,)\n",
        "# if K.image_data_format() == 'channels_first':\n",
        "#     df_train = df_train.reshape(df_train.shape[0], IMAGE_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
        "#     df_val = df_val.reshape(df_val.shape[0], 1, IMAGE_SIZE, IMAGE_SIZE)\n",
        "#     input_shape = (1, img_rows, img_cols)\n",
        "# else:\n",
        "#     df_train = df_train.reshape(df_train.shape[0], IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)\n",
        "#     df_val = df_val.reshape(df_val.shape[0], IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)\n",
        "#     input_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)\n",
        "print(df_train.shape)\n",
        "print(df_val.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14000, 2)\n",
            "(3500, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CkGlNNp2Bs8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "761b6bd6-aa48-4ec2-8e28-4a2d991b5756"
      },
      "source": [
        "if not os.path.exists('test'):\n",
        "  os.mkdir('test')\n",
        "if not os.path.exists('test/test'):\n",
        "  os.mkdir('test/test')\n",
        "!mv test/* test/test/"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot move 'test/test' to a subdirectory of itself, 'test/test/test'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYGPGP3QDCVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_list = list(df_train['id'])\n",
        "val_list = list(df_val['id'])\n",
        "\n",
        "\n",
        "\n",
        "# Transfer the train images\n",
        "\n",
        "for image in train_list:\n",
        "    \n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image\n",
        "    # get the label for a certain image\n",
        "    target = train.loc[image,'has_cactus']\n",
        "    \n",
        "    # these must match the folder names\n",
        "    if target == 0:\n",
        "        label = 'has_no_cactus'\n",
        "    if target == 1:\n",
        "        label = 'has_cactus'\n",
        "    \n",
        "    # source path to image\n",
        "    src = os.path.join('train', fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(train_dir, label, fname)\n",
        "    # copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "# Transfer the val images\n",
        "\n",
        "for image in val_list:\n",
        "    \n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image\n",
        "    # get the label for a certain image\n",
        "    target = train.loc[image,'has_cactus']\n",
        "    \n",
        "    # these must match the folder names\n",
        "    if target == 0:\n",
        "        label = 'has_no_cactus'\n",
        "    if target == 1:\n",
        "        label = 'has_cactus'\n",
        "    \n",
        "\n",
        "    # source path to image\n",
        "    src = os.path.join('train', fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(val_dir, label, fname)\n",
        "    # copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N10CtSzPY6OS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE = 32\n",
        "IMAGE_CHANNELS = 3\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC55FNURDx56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = 'train_dir'\n",
        "valid_path = 'val_dir'\n",
        "\n",
        "num_train_samples = len(df_train)\n",
        "num_val_samples = len(df_val)\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "\n",
        "\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svIATXCDYMNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "203b8d8a-9d4c-4309-bb4b-067368c2909f"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255,\n",
        "                             horizontal_flip = True,\n",
        "                             vertical_flip = True,\n",
        "                             featurewise_center = True,\n",
        "                             samplewise_center = True,\n",
        "                             featurewise_std_normalization = True,\n",
        "                             samplewise_std_normalization = True\n",
        "                            )\n",
        "\n",
        "train_gen = datagen.flow_from_directory(train_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=train_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "val_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=val_batch_size,\n",
        "                                        class_mode='categorical')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14000 images belonging to 2 classes.\n",
            "Found 3500 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwyoN2YEZMOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1084698-69fe-4fff-8f0f-5e676c89cfb8"
      },
      "source": [
        "print(val_gen.class_indices)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'has_cactus': 0, 'has_no_cactus': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iftYl81zZczp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "963e8011-1938-4d66-d31e-42efcd7ecebf"
      },
      "source": [
        "kernel_size = (3,3)\n",
        "pool_size= (2,2)\n",
        "first_filters = 32\n",
        "second_filters = 64\n",
        "\n",
        "dropout_conv = 0.3\n",
        "dropout_dense = 0.3\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size)) \n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(dropout_dense))\n",
        "model.add(Dense(2, activation = \"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 9, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               147712    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 259,970\n",
            "Trainable params: 259,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stxDJvujc0hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(Adam(lr=0.0001), loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGCJ8H0ZdHex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1533
        },
        "outputId": "9ed74a3f-04ee-406f-8d92-cfa06d268f46"
      },
      "source": [
        "if not os.path.exists('MLModels'):\n",
        "  os.mkdir('MLModels')\n",
        "filepath = \"MLModels/Cactus-identification.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n",
        "                                   verbose=1, mode='max', min_lr=0.00001)\n",
        "                              \n",
        "                              \n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=val_steps,\n",
        "                    epochs=15, verbose=1,\n",
        "                   callbacks=callbacks_list)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:699: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:707: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "350/350 [==============================] - 5s 13ms/step - loss: 0.1080 - acc: 0.9597\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.95971, saving model to MLModels/Cactus-identification.h5\n",
            "1400/1400 [==============================] - 56s 40ms/step - loss: 0.1756 - acc: 0.9281 - val_loss: 0.1080 - val_acc: 0.9597\n",
            "Epoch 2/15\n",
            "350/350 [==============================] - 5s 14ms/step - loss: 0.0693 - acc: 0.9726\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.95971 to 0.97257, saving model to MLModels/Cactus-identification.h5\n",
            "1400/1400 [==============================] - 47s 34ms/step - loss: 0.0949 - acc: 0.9639 - val_loss: 0.0693 - val_acc: 0.9726\n",
            "Epoch 3/15\n",
            "350/350 [==============================] - 4s 12ms/step - loss: 0.0626 - acc: 0.9771\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.97257 to 0.97714, saving model to MLModels/Cactus-identification.h5\n",
            "1400/1400 [==============================] - 46s 33ms/step - loss: 0.0693 - acc: 0.9744 - val_loss: 0.0626 - val_acc: 0.9771\n",
            "Epoch 4/15\n",
            "350/350 [==============================] - 4s 12ms/step - loss: 0.0402 - acc: 0.9863\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.97714 to 0.98629, saving model to MLModels/Cactus-identification.h5\n",
            "1400/1400 [==============================] - 46s 33ms/step - loss: 0.0554 - acc: 0.9791 - val_loss: 0.0402 - val_acc: 0.9863\n",
            "Epoch 5/15\n",
            "350/350 [==============================] - 4s 12ms/step - loss: 0.0344 - acc: 0.9843\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.98629\n",
            "1400/1400 [==============================] - 45s 32ms/step - loss: 0.0503 - acc: 0.9827 - val_loss: 0.0344 - val_acc: 0.9843\n",
            "Epoch 6/15\n",
            "350/350 [==============================] - 4s 12ms/step - loss: 0.0373 - acc: 0.9860\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.98629\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "1400/1400 [==============================] - 46s 33ms/step - loss: 0.0457 - acc: 0.9835 - val_loss: 0.0373 - val_acc: 0.9860\n",
            "Epoch 7/15\n",
            "350/350 [==============================] - 4s 12ms/step - loss: 0.0333 - acc: 0.9871\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.98629 to 0.98714, saving model to MLModels/Cactus-identification.h5\n",
            "1400/1400 [==============================] - 44s 32ms/step - loss: 0.0397 - acc: 0.9849 - val_loss: 0.0333 - val_acc: 0.9871\n",
            "Epoch 8/15\n",
            "350/350 [==============================] - 4s 12ms/step - loss: 0.0267 - acc: 0.9897\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.98714 to 0.98971, saving model to MLModels/Cactus-identification.h5\n",
            "1400/1400 [==============================] - 46s 33ms/step - loss: 0.0366 - acc: 0.9872 - val_loss: 0.0267 - val_acc: 0.9897\n",
            "Epoch 9/15\n",
            "350/350 [==============================] - 5s 15ms/step - loss: 0.0283 - acc: 0.9906\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.98971 to 0.99057, saving model to MLModels/Cactus-identification.h5\n",
            "1400/1400 [==============================] - 46s 33ms/step - loss: 0.0347 - acc: 0.9884 - val_loss: 0.0283 - val_acc: 0.9906\n",
            "Epoch 10/15\n",
            "350/350 [==============================] - 4s 12ms/step - loss: 0.0260 - acc: 0.9894\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99057\n",
            "1400/1400 [==============================] - 45s 32ms/step - loss: 0.0337 - acc: 0.9885 - val_loss: 0.0260 - val_acc: 0.9894\n",
            "Epoch 11/15\n",
            "350/350 [==============================] - 4s 12ms/step - loss: 0.0296 - acc: 0.9880\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.99057\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "1400/1400 [==============================] - 46s 33ms/step - loss: 0.0339 - acc: 0.9875 - val_loss: 0.0296 - val_acc: 0.9880\n",
            "Epoch 12/15\n",
            "350/350 [==============================] - 4s 12ms/step - loss: 0.0321 - acc: 0.9871\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.99057\n",
            "1400/1400 [==============================] - 44s 32ms/step - loss: 0.0284 - acc: 0.9905 - val_loss: 0.0321 - val_acc: 0.9871\n",
            "Epoch 13/15\n",
            "350/350 [==============================] - 4s 12ms/step - loss: 0.0266 - acc: 0.9900\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.99057\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "1400/1400 [==============================] - 46s 33ms/step - loss: 0.0279 - acc: 0.9891 - val_loss: 0.0266 - val_acc: 0.9900\n",
            "Epoch 14/15\n",
            "350/350 [==============================] - 4s 12ms/step - loss: 0.0246 - acc: 0.9911\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.99057 to 0.99114, saving model to MLModels/Cactus-identification.h5\n",
            "1400/1400 [==============================] - 45s 32ms/step - loss: 0.0245 - acc: 0.9921 - val_loss: 0.0246 - val_acc: 0.9911\n",
            "Epoch 15/15\n",
            "350/350 [==============================] - 4s 12ms/step - loss: 0.0231 - acc: 0.9920\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.99114 to 0.99200, saving model to MLModels/Cactus-identification.h5\n",
            "1400/1400 [==============================] - 46s 33ms/step - loss: 0.0237 - acc: 0.9925 - val_loss: 0.0231 - val_acc: 0.9920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIoq0UzzD5nC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "has_cactus_sample = img_to_array(load_img('train_dir/has_cactus/0148bb4a295cf49c0169d69a4a63df7e.jpg'))\n",
        "has_no_cactus_sample = img_to_array(load_img('train_dir/has_no_cactus/04108a6d0299da92ebee86db8fc77bb0.jpg'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbqC3gedF67W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "04eea9dd-0847-4870-94a7-94ca4fe0e6a5"
      },
      "source": [
        "model = load_model('MLModels/Cactus-identification.h5')\n",
        "\n",
        "pred_1 = np.argmax(model.predict(has_cactus_sample.reshape(1,  IMAGE_SIZE, IMAGE_SIZE,IMAGE_CHANNELS,)))\n",
        "pred_2 = np.argmax(model.predict(has_no_cactus_sample.reshape(1,  IMAGE_SIZE, IMAGE_SIZE,IMAGE_CHANNELS,)))\n",
        "rev_dict = {v:k for k,v in val_gen.class_indices.items()}\n",
        "print(pred_1,pred_2)\n",
        "print(rev_dict[pred_1],rev_dict[pred_2])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1\n",
            "has_cactus has_no_cactus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k20BGAVXca3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f88a1ed8-f8ad-4c97-a03f-505dde78d33e"
      },
      "source": [
        "test_gen = datagen.flow_from_directory(directory=r\"./test\",\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=1,\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4000 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZWGS9LYgtd9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "538e70e2-dfff-4609-a027-78dac606159a"
      },
      "source": [
        "prediction = model.predict_generator(test_gen,steps = len(test_gen))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:699: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:707: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}